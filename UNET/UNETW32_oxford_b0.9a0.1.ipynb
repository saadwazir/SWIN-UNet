{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxford IIIT image segmentation with SwinUNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_n = 6\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "'''\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[g_n], 'GPU')\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from keras_vision_transformer import swin_layers\n",
    "from keras_vision_transformer import transformer_layers\n",
    "from keras_vision_transformer import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and problem statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example applies the dataset of [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) (Parkhi et al. 2012). This dataset contains images of pets and their pixel-wise mask that indicates (1) pixels belonging to the pet, (2) pixels bordering the pet, and (3) surrounding pixels.\n",
    "\n",
    "A semantic segmentation problem is proposed; it takes images as inputs and predicts the classification probability of the three pixel-wise masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the indicator of a fresh run\n",
    "first_time_running = False\n",
    "\n",
    "# user-specified working directory\n",
    "filepath = '/mnt/hdd_2A/segment_ai_ml_project/datasets/oxford_pets_clean/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "n_labels = 3\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = MaxPool2D(pool_size=(2,2))(inputs)\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_effienet_unet(input_shape, num_filters):\n",
    "    \"\"\" Input \"\"\"\n",
    "    IN = Input(input_shape)\n",
    "    e1 = conv_block(IN, num_filters[0])\n",
    "    \n",
    "    \"\"\" Encoder \"\"\"\n",
    "    e2 = encoder_block(e1, num_filters[1])\n",
    "    e3 = encoder_block(e2, num_filters[2])\n",
    "    e4 = encoder_block(e3, num_filters[3])\n",
    "    b1 = encoder_block(e4, num_filters[4])\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, e4, num_filters[3])                      \n",
    "    d2 = decoder_block(d1, e3, num_filters[2])                         \n",
    "    d3 = decoder_block(d2, e2, num_filters[1])                             \n",
    "    d4 = decoder_block(d3, e1, num_filters[0])                               \n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    OUT = Conv2D(n_labels, kernel_size=1, use_bias=False, activation='softmax')(d4)\n",
    "\n",
    "    model = Model(inputs=[IN,], outputs=[OUT,], name=\"UNet\")\n",
    "    return model\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "num_filters = [32, 64, 128, 256, 512]\n",
    "model = build_effienet_unet(input_shape, num_filters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Hyperparameters of the Swin-UNET are listed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "## IOU in pure numpy\n",
    "def numpy_iou(y_true, y_pred, n_class=3):\n",
    "    def iou(y_true, y_pred, n_class):\n",
    "        # IOU = TP/(TP+FN+FP)\n",
    "        IOU = []\n",
    "        for c in range(n_class):\n",
    "            TP = np.sum((y_true == c) & (y_pred == c))\n",
    "            FP = np.sum((y_true != c) & (y_pred == c))\n",
    "            FN = np.sum((y_true == c) & (y_pred != c))\n",
    "\n",
    "            n = TP\n",
    "            d = float(TP + FP + FN + 1e-12)\n",
    "\n",
    "            iou = np.divide(n, d)\n",
    "            IOU.append(iou)\n",
    "\n",
    "        return np.mean(IOU)\n",
    "\n",
    "    batch = y_true.shape[0]\n",
    "    y_true = np.reshape(y_true, (batch, -1))\n",
    "    y_pred = np.reshape(y_pred, (batch, -1))\n",
    "\n",
    "    score = []\n",
    "    for idx in range(batch):\n",
    "        iou_value = iou(y_true[idx], y_pred[idx], n_class)\n",
    "        score.append(iou_value)\n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "## Calculating IOU across a range of thresholds, then we will mean all the\n",
    "## values of IOU's.\n",
    "## this function can be used as keras metrics\n",
    "def numpy_mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5,1.0,1.0):\n",
    "        y_pred_ = tf.cast(y_pred > t, tf.int32)\n",
    "        score = tf.numpy_function(numpy_iou, [y_true, y_pred_], tf.float64)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import segmentation_models as sm\n",
    "\n",
    "dice_loss = sm.losses.DiceLoss() \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "jaccard_loss = sm.losses.JaccardLoss()\n",
    "binary_focal_loss = sm.losses.BinaryFocalLoss()\n",
    "binary_CE_loss = sm.losses.BinaryCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam. of the losses\n",
    "alpha = 0.1       # Binary CE\n",
    "beta = 0.9        # Dice\n",
    "gamma = 0       # Focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total losses\n",
    "total_loss = alpha * binary_CE_loss + beta * dice_loss + gamma * focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "# <---- !!! gradient clipping is important\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4, clipvalue=0.5)\n",
    "model.compile(loss=total_loss, optimizer=opt)\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "The input of RGB images are resized to 128-by-128 through the nearest neighbour scheme, and then normalized to the interval of [0, 1]. The training target of pixel-wise masks are resized similarly.\n",
    "\n",
    "A random split is applied with 80%, 10%, 10% of the samples are assigned for training, validation, and testing, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data_process(input_array):\n",
    "    '''converting pixel vales to [0, 1]'''\n",
    "    return input_array/255.\n",
    "\n",
    "def target_data_process(target_array):\n",
    "    '''Converting tri-mask of {1, 2, 3} to three categories.'''\n",
    "    return keras.utils.to_categorical(target_array-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = np.array(sorted(glob(filepath+'images/*.jpg')))\n",
    "label_names = np.array(sorted(glob(filepath+'annotations/trimaps/*.png')))\n",
    "\n",
    "# Make a Constant Seed\n",
    "np.random.seed(42)\n",
    "\n",
    "L = len(sample_names)\n",
    "ind_all = np.arange(L)\n",
    "np.random.shuffle(ind_all)\n",
    "\n",
    "print(L)\n",
    "print(ind_all)\n",
    "\n",
    "L_train = int(0.8*L); L_valid = int(0.1*L); L_test = L - L_train - L_valid\n",
    "ind_train = ind_all[:L_train]; ind_valid = ind_all[L_train:L_train+L_valid]; ind_test = ind_all[L_train+L_valid:]\n",
    "print(\"Training:validation:testing = {}:{}:{}\".format(L_train, L_valid, L_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input = input_data_process(utils.image_to_array(sample_names[ind_valid], size=128, channel=3))\n",
    "valid_target = target_data_process(utils.image_to_array(label_names[ind_valid], size=128, channel=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = input_data_process(utils.image_to_array(sample_names[ind_test], size=128, channel=3))\n",
    "test_target = target_data_process(utils.image_to_array(label_names[ind_test], size=128, channel=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The segmentation model is trained with fixed 15 epoches. Each epoch containts 100 batches and each batch contains 32 samples.\n",
    "\n",
    "*The training process here is far from systematic, and is provided for illustration purposes only.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epoch = 120 # number of epoches\n",
    "N_batch = 100 # number of batches per epoch\n",
    "N_sample = 32 # number of samples per batch\n",
    "\n",
    "tol = 0 # current early stopping patience\n",
    "max_tol = 120 # the max-allowed early stopping patience\n",
    "min_del = 0 # the lowest acceptable loss value reduction \n",
    "\n",
    "logs = {}\n",
    "\n",
    "# loop over epoches\n",
    "for epoch in range(N_epoch):\n",
    "    \n",
    "    # initial loss record\n",
    "    if epoch == 0:\n",
    "        y_pred = model.predict([valid_input])\n",
    "        record = np.mean( alpha * binary_CE_loss(valid_target, y_pred) + beta * dice_loss(valid_target, y_pred) + gamma * focal_loss(valid_target, y_pred) )\n",
    "        loss_ = 0\n",
    "        \n",
    "        print(\"Epoch: Initial\")\n",
    "        print('Initial Validation loss = {}'.format(record))\n",
    "        valid_miou = np.mean( numpy_mean_iou(valid_target, y_pred) )\n",
    "        print(\"mIoU: \", valid_miou)\n",
    "    \n",
    "    # loop over batches\n",
    "    for step in range(N_batch):\n",
    "        # selecting smaples for the current batch\n",
    "        ind_train_shuffle = utils.shuffle_ind(L_train)[:N_sample]\n",
    "        \n",
    "        # batch data formation\n",
    "        ## augmentation is not applied\n",
    "        train_input = input_data_process(\n",
    "            utils.image_to_array(sample_names[ind_train][ind_train_shuffle], size=128, channel=3))\n",
    "        train_target = target_data_process(\n",
    "            utils.image_to_array(label_names[ind_train][ind_train_shuffle], size=128, channel=1))\n",
    "        \n",
    "        # train on batch\n",
    "        loss_ = model.train_on_batch([train_input,], [train_target,])\n",
    "        \n",
    "    # epoch-end validation\n",
    "    y_pred = model.predict([valid_input])\n",
    "    record_temp = np.mean( alpha * binary_CE_loss(valid_target, y_pred) + beta * dice_loss(valid_target, y_pred) + gamma * focal_loss(valid_target, y_pred) )\n",
    "\n",
    "    # if loss is reduced\n",
    "    if record - record_temp > min_del:\n",
    "        print(\"Epoch: \", (epoch+1))\n",
    "        print('Validation performance is improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp # update the loss record\n",
    "        tol = 0; # refresh early stopping patience\n",
    "        # ** model checkpoint is not stored ** #\n",
    "\n",
    "    # if loss not reduced\n",
    "    else:\n",
    "        print(\"Epoch: \", (epoch+1))\n",
    "        print('Validation performance {} is NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    valid_miou = np.mean(numpy_mean_iou(valid_target, y_pred) )\n",
    "    print(\"Validation mIoU: \", valid_miou)\n",
    "    \n",
    "    # ** train, validation loss & validation MIoU are NOW stored! ** #\n",
    "    logs[epoch] = (loss_, record_temp, valid_miou)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new path\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "path = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For logging\n",
    "itemlist = logs.items()\n",
    "\n",
    "f = open(path + \"/log.txt\", 'w')\n",
    "data = \"epoch\" + \"\\t\" + \"Train Loss\" + \"\\t\\t\\t\\t\" + \"Val Loss\" + \"\\t\\t\" + \"Val mIoU\\n\"\n",
    "f.write(data)\n",
    " \n",
    "for item in itemlist:\n",
    "    print(item)\n",
    "    data = str(item[0]) + \"\\t\\t\" + str(item[1][0]) + \"\\t\\t\" + str(item[1][1]) + \"\\t\\t\" + str(item[1][2]) + \"\\t\\t\\n\"\n",
    "    f.write(data)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The testing set performance is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([test_input,])\n",
    "# print('Testing set cross-entropy loss = {}'.format(np.mean(keras.losses.categorical_crossentropy(test_target, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = np.mean( dice_loss(test_target, y_pred) )\n",
    "f = np.mean( focal_loss(test_target, y_pred) )\n",
    "ce = np.mean( binary_CE_loss(test_target, y_pred) )\n",
    "tot = np.mean ( alpha * binary_CE_loss(test_target, y_pred) + beta * dice_loss(test_target, y_pred) + gamma * focal_loss(test_target, y_pred) )\n",
    "\n",
    "print(\"TEST Dice Loss : \", d)\n",
    "print(\"TEST Focal Loss : \", f)\n",
    "print(\"TEST BCE Loss : \", ce)\n",
    "print(\"TEST Total Loss : \", tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.mean( numpy_mean_iou(test_target, y_pred) )\n",
    "print(\"TEST mIoU : \", r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_decorate_box(ax):\n",
    "    [j.set_linewidth(0) for j in ax.spines.values()]\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, \n",
    "                   labelbottom=False, left=False, right=False, labelleft=False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show & Save Test Images\n",
    "num_sample = 30\n",
    "\n",
    "for i in range(num_sample):\n",
    "    fig, AX = plt.subplots(1, 4, figsize=(13, (13-0.2)/4))\n",
    "    plt.subplots_adjust(0, 0, 1, 1, hspace=0.1, wspace=0.1)\n",
    "\n",
    "    for ax in AX:\n",
    "        ax = ax_decorate_box(ax)\n",
    "\n",
    "    AX[0].pcolormesh(test_target[i, ..., ], cmap=plt.cm.jet)\n",
    "    AX[1].pcolormesh(y_pred[i, ..., 0], cmap=plt.cm.jet)\n",
    "    AX[2].pcolormesh(y_pred[i, ..., 1], cmap=plt.cm.jet)\n",
    "    AX[3].pcolormesh(y_pred[i, ..., 2], cmap=plt.cm.jet)\n",
    "\n",
    "    AX[0].set_title(\"Original\", fontsize=14)\n",
    "    AX[1].set_title(\"Pixels belong to the object\", fontsize=14)\n",
    "    AX[2].set_title(\"Surrounding pixels\", fontsize=14)\n",
    "    AX[3].set_title(\"Bordering pixels\", fontsize=14)\n",
    "    \n",
    "    plt.savefig( path + '/test_' + str(i) + '.png')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
